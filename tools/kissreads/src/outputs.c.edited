/**
 * Copyright INRIA , contributors Peterlongo
 * pierre.peterlongo@inria.fr
 *
 *
 * This software is a computer program whose purpose is to detect the
 * presence of a starter in a set of NGS reads, and to provide the neighbor
 * in case of success..
 *
 * This software is governed by the CeCILL license under French law and
 * abiding by the rules of distribution of free software.  You can  use,
 * modify and/ or redistribute the software under the terms of the CeCILL
 * license as circulated by CEA, CNRS and INRIA at the following URL
 * "http://www.cecill.info".

 * As a counterpart to the access to the source code and  rights to copy,
 * modify and redistribute granted by the license, users are provided only
 * with a limited warranty  and the software's author,  the holder of the
 * economic rights,  and the successive licensors  have only  limited
 * liability.

 * In this respect, the user's attention is drawn to the risks associated
 * with loading,  using,  modifying and/or developing or reproducing the
 * software by the user in light of its specific status of free software,
 * that may mean  that it is complicated to manipulate,  and  that  also
 * therefore means  that it is reserved for developers  and  experienced
 * professionals having in-depth computer knowledge. Users are therefore
 * encouraged to load and test the software's suitability as regards their
 * requirements in conditions enabling the security of their systems and/or
 * data to be ensured and,  more generally, to use and operate it in the
 * same conditions as regards security.
 *
 * The fact that you are presently reading this means that you have had
 * knowledge of the CeCILL license and that you accept its terms.
 */

/*
 * outputs.c
 *
 *  Created on: 27 oct. 2010
 *      Author: ppeterlo
 */
#include <fragment_index.h>
#include <fragment_info.h>
#include <commons.h>
#include <string.h>
#include <tree.h>
#include <limits.h>
#include <math.h>
#define MAX(a,b) ((a) > (b) ? (a) : (b))
#define MIN(a,b) ((a) < (b) ? (a) : (b))
#define ABS(a) (((a) < 0) ? -(a) : (a))

//#define COVERAGE // PROVIDES A COVERAGE PER POSITION --> COMMENT THIS LINE PROVIDES READS STARTING PER POSITION
//#define DEBUG_QUALITY
//#define KMER_SPANNING // ask more than only all position covered by at least min_coverage reads. Each kmer spanning each position should be covered by at least min_coverage reads. 

#if !HAVE_LOG2F
#define log2f log
#endif

// Operation made on each data set (read_set_id)
//#define op() MIN(corrected_avg_lo[read_set_id],corrected_avg_up[read_set_id]) /	(corrected_avg_lo[read_set_id]+corrected_avg_up[read_set_id]);
#define op() corrected_avg_up[read_set_id] /	(corrected_avg_lo[read_set_id]+corrected_avg_up[read_set_id]);




float rank_max(const float * corrected_avg_up, const float * corrected_avg_lo, const int number_of_read_sets){
	int read_set_id;
	float rank=0;
	float temp;
	//	float sum=0;
	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
		if(corrected_avg_lo[read_set_id]+corrected_avg_up[read_set_id]){ // not null in the 2 isoforms
			temp = op()
			if(temp > rank)
				rank = temp;
		}
	}
	return rank;
}

float rank_min(const float * corrected_avg_up, const float * corrected_avg_lo, const int number_of_read_sets){
	int read_set_id;
	float rank=INT_MAX;
	float temp;
	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
		if(corrected_avg_lo[read_set_id]+corrected_avg_up[read_set_id]){ // not null in the 2 isoforms
			temp = op()
			if(temp < rank)
				rank = temp;
		}
	}
	return rank;
}

float rank_sum(const float * corrected_avg_up, const float * corrected_avg_lo, const int number_of_read_sets){
	int read_set_id;
	float rank=0;
	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
		if(corrected_avg_lo[read_set_id]+corrected_avg_up[read_set_id]){ // not null in the 2 isoforms
			rank += op()
		}
	}
	return rank;
}

float rank_avg(const float * corrected_avg_up, const float * corrected_avg_lo, const int number_of_read_sets){
	return rank_sum(corrected_avg_up,corrected_avg_lo,number_of_read_sets)/(float)number_of_read_sets;
}

float rank_standard_deviation (const float * corrected_avg_up, const float * corrected_avg_lo, const int number_of_read_sets){
	float avg= rank_avg(corrected_avg_up,corrected_avg_lo,number_of_read_sets);
	float temp;
	float sdev=0.0;
	float sum=0.0;
	int read_set_id;
	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
		if(corrected_avg_lo[read_set_id]+corrected_avg_up[read_set_id]){ // not null in the 2 isoforms
			temp=op()
			sum+=pow(temp-avg,2);
		}
	}
	sdev=sum/(number_of_read_sets-1);
	sdev = sqrt(sdev);
	return sdev;
}

/**
 * TODO: the entropy function raises some problems: any path having zero value creates a -inf value with the log of the fraction...
 */
float rank_entropy(const float * corrected_avg_up, const float * corrected_avg_lo, const int number_of_read_sets){
        int read_set_id;
	float ranksum=rank_sum(corrected_avg_up,corrected_avg_lo,number_of_read_sets);
	float temp;
	float entropy = 0.0;
	float fraction;
//	printf("hey (sum =%f): ",ranksum);
	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
//		printf("(%f/%f) ", corrected_avg_lo[read_set_id], corrected_avg_up[read_set_id]);
		if(corrected_avg_lo[read_set_id]+corrected_avg_up[read_set_id]){ // not null in the 2 isoforms
			temp=op()
			fraction = temp/ranksum;
//			printf("[fraction=%f] ",fraction);
			entropy -= (fraction * log2f (fraction));
		}
	}
//	printf(" --> %f\n", entropy);
	return entropy;
}

/*Calculates the phi coefficient of 2*2 contingency table. Value close to 1 indicates an association between the alleles and the conditions.*/
/*Note that this value is valid if at least 3 out of the 4 values are non 0, or if the .Otherwise it output -1*/
float phi(int a,int b, int c,int d) {
<<<<<<< .mine
  int denom=sqrt((a+b)*(c+d)*(a+c)*(b+d));
  if (denom==0) 
    return 0;
  float Phi = (a*d-b*c)/denom;
    return Phi;
=======
//  int denom=(a+b)*(c+d)*(a+c)*(b+d);
//  if (denom==0) 
//    return 0;
//  float Phi = (a*d-b*c)/sqrt(denom);
//  return Phi;
    if((a+b)==0) return 0;
    if((c+d)==0) return 0;
    if((a+c)==0) return 0;
    if((b+d)==0) return 0;
    // avoid the computation of denom, possibly bigger than an int or an unsigned long long int...
    return (a*d-b*c)/(sqrt((float)(a+b))*sqrt((float)(c+d))*sqrt((float)(a+c))*sqrt((float)(b+d)));
>>>>>>> .r5165
}

/*Computes all pairwise phi values for all pairs of conditions and returns the max*/
float rank_phi(const int *sum_up, const int *sum_lo, const int number_of_read_sets) {
    float phimax=0;
    if (number_of_read_sets==1)
        return 0;
    else
    {
        int i,j;
        float phicur=0;
        for (i=0;i<number_of_read_sets;i++)
            for (j=i+1;j<number_of_read_sets;j++)
            {
                phicur=phi(sum_up[i],sum_up[j],sum_lo[i],sum_lo[j]);
                phimax=MAX(phimax,ABS(phicur));
            }
    }
    return phimax;
}

#ifdef COVERAGE

/**
 * prints a couple using the coverage instead of read starting per position
 */
/*void print_couple_i(char * comment, FILE* out, const char* prefix, const p_fragment_info ** results_against_set, int cycle_id, int number_of_read_sets, int qual){
	int j;
	// on upper path
	float avg_up[number_of_read_sets] ; // avg_up[i] = read set i on upper path
	float corrected_avg_up[number_of_read_sets] ;
	int min_up[number_of_read_sets] ;
	int max_up[number_of_read_sets] ;
	// on lower path
	float avg_lo[number_of_read_sets] ; // avg_lo[i] = read set i on lower path
	float corrected_avg_lo[number_of_read_sets] ;
	int min_lo[number_of_read_sets] ;
	int max_lo[number_of_read_sets] ;



	int read_set_id;
	//	float sum=0;
	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
		/// UPPER
		compute_uncorrected_and_corrected_avg_i(results_against_set[read_set_id][cycle_id], &avg_up[read_set_id], &corrected_avg_up[read_set_id],&min_up[read_set_id], &max_up[read_set_id]);
		/// LOWER
		compute_uncorrected_and_corrected_avg_i(results_against_set[read_set_id][cycle_id+1], &avg_lo[read_set_id], &corrected_avg_lo[read_set_id],&min_lo[read_set_id], &max_lo[read_set_id]);
	}


//	float rank = rank_max(corrected_avg_up,corrected_avg_lo,number_of_read_sets);
//	float rank = rank_min(corrected_avg_up,corrected_avg_lo,number_of_read_sets);
//	float rank = rank_avg(corrected_avg_up,corrected_avg_lo,number_of_read_sets);
	float rank = rank_standard_deviation(corrected_avg_up,corrected_avg_lo,number_of_read_sets);
//	float rank = rank_sum(corrected_avg_up,corrected_avg_lo,number_of_read_sets);
//	float rank = rank_entropy(corrected_avg_up,corrected_avg_lo,number_of_read_sets);

	// probleme du calcul de l'entropie:
	//  1° délicat pour des valeurs continue...
	//  2° le ratio d'inclusion n'existe que pour le splicing !!!

	// Suggestion: ecart type ? min, max, sum, user defined among a list: depends on the study...
	//    float rank = 0.0;  //entropy
	//	// ENTROPY OF inclusion ratio
	//	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
	//		float p_i = 0;
	//		if(corrected_avg_lo[read_set_id]+corrected_avg_up[read_set_id]) // avoid zero division
	//			p_i  = ((int)(1000*corrected_avg_lo[read_set_id]/(corrected_avg_lo[read_set_id]+corrected_avg_up[read_set_id]))) / sum;
	//		if (p_i > 0.0)  //avoid the inf value returned by log(0.0)
	//			rank -= p_i * (log(p_i) / log(2));
	//	}



	// UPPER PATH
	fprintf(out, "%2f >%s%s|", rank, comment,results_against_set[0][cycle_id]->comment);
	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
		fprintf(out, "C%d_%d<%.2f_%.2f<%d|",read_set_id+1,min_up[read_set_id], avg_up[read_set_id], corrected_avg_up[read_set_id],max_up[read_set_id]);

	fprintf(out, "rank_%.5f",rank);
	fprintf(out, ";%s", results_against_set[0][cycle_id]->w);
	if(whole_coverage){
		for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
			fprintf(out, "_covbyposagainstC%d_",read_set_id+1);
			for(j=0;j<strlen(results_against_set[read_set_id][cycle_id]->w);j++)
				fprintf(out, "%d_", results_against_set[read_set_id][cycle_id]->read_coherent_positions[j]);
		}
	}
	fprintf(out, ";");

	// LOWER PATH
	fprintf(out, ">%s%s|", comment, results_against_set[0][cycle_id+1]->comment);
	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
		fprintf(out, "C%d_%d<%.2f_%.2f<%d|",read_set_id+1,min_lo[read_set_id], avg_lo[read_set_id], corrected_avg_lo[read_set_id],max_lo[read_set_id]);

	fprintf(out, "rank_%.5f",rank);
	fprintf(out, ";%s", results_against_set[0][cycle_id+1]->w);
	if(whole_coverage){
		for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
			fprintf(out, "_covbyposagainstC%d_",read_set_id+1);
			for(j=0;j<strlen(results_against_set[read_set_id][cycle_id+1]->w);j++)
				fprintf(out, "%d_", results_against_set[read_set_id][cycle_id+1]->read_coherent_positions[j]);
		}
	}
	fprintf(out, "\n");

	if( qual ){
		//RALUCA: don't know yet what to do in this case, this function is not actually used in the current version of kissReads for kisSplice
	}
}*/
#else

/**
 * prints a couple using the reads starting position instead of coverage per position
 */
void print_couple_i(char * comment, FILE* out, const char* prefix, const p_fragment_info * results_against_set, int cycle_id, int number_of_read_sets, int qual, const char map_snps){
	int j;
	// on upper path
	int sum_up[number_of_read_sets] ;
//	int min_up[number_of_read_sets] ;
//	int max_up[number_of_read_sets] ;
	// on lower path
	int sum_lo[number_of_read_sets] ;
//	int min_lo[number_of_read_sets] ;
//	int max_lo[number_of_read_sets] ;
	int avg_up[number_of_read_sets];
	int avg_lo[number_of_read_sets];
	int read_set_id;
	 
	if( qual ){
	  // we are providing results for generic dataset
	  if(!map_snps){
	    for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
	      const int central_pos = (strlen(results_against_set[cycle_id]->w)/2)+1; // the length of the path should be odd
	      avg_up[read_set_id] = 0;
	      avg_lo[read_set_id] = 0;
	      if(results_against_set[cycle_id]->read_coherent_positions[read_set_id][central_pos])
#ifdef CHARQUAL // with charqual, average qual value is already computed
              avg_up[read_set_id] = results_against_set[cycle_id]->sum_quality_per_position[read_set_id][central_pos];
#else
              avg_up[read_set_id] = results_against_set[cycle_id]->sum_quality_per_position[read_set_id][central_pos] / results_against_set[cycle_id]->read_coherent_positions[read_set_id][central_pos];
#endif
	      if(results_against_set[cycle_id+1]->read_coherent_positions[read_set_id][central_pos])
#ifdef CHARQUAL
              avg_lo[read_set_id] = results_against_set[cycle_id+1]->sum_quality_per_position[read_set_id][central_pos] ;
#else
              avg_lo[read_set_id] = results_against_set[cycle_id+1]->sum_quality_per_position[read_set_id][central_pos] / results_against_set[cycle_id+1]->read_coherent_positions[read_set_id][central_pos];

#endif
	    }
	  }
	  else{ // we are providing results for a SNP, we give outputs only for the central position
          
          //compute average quality for the variant (position quality if SNP)
          for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
              avg_up[read_set_id] = 0;
              const int snp_pos = strlen(results_against_set[cycle_id]->w)/2;
              j=snp_pos;
//              for (j=kmer_size-1;j<=strlen(results_against_set[cycle_id]->w)-kmer_size;j++)
                  if(results_against_set[cycle_id]->read_coherent_positions[read_set_id][j])
#ifdef CHARQUAL
                      avg_up[read_set_id] = avg_up[read_set_id] + results_against_set[cycle_id]->sum_quality_per_position[read_set_id][j];
#else
              avg_up[read_set_id] = avg_up[read_set_id] + (results_against_set[cycle_id]->sum_quality_per_position[read_set_id][j] / results_against_set[cycle_id]->read_coherent_positions[read_set_id][j]);
#endif
//              avg_up[read_set_id] = avg_up[read_set_id] / (strlen(results_against_set[cycle_id]->w) - 2*kmer_size + 2);
          }
          //compute average quality for the variant (position quality if SNP)
          for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
              avg_lo[read_set_id] = 0;
              const int snp_pos = strlen(results_against_set[cycle_id+1]->w)/2;
              j=snp_pos;
//              for (j=kmer_size-1;j<=strlen(results_against_set[cycle_id+1]->w)-kmer_size;j++)
                  if(results_against_set[cycle_id+1]->read_coherent_positions[read_set_id][j])
#ifdef CHARQUAL
                      avg_lo[read_set_id] = avg_lo[read_set_id] + results_against_set[cycle_id+1]->sum_quality_per_position[read_set_id][j];
#else
              avg_lo[read_set_id] = avg_lo[read_set_id] + (results_against_set[cycle_id+1]->sum_quality_per_position[read_set_id][j] / results_against_set[cycle_id+1]->read_coherent_positions[read_set_id][j]);
#endif
//              avg_lo[read_set_id] = avg_lo[read_set_id] / (strlen(results_against_set[cycle_id+1]->w) - 2*kmer_size + 2);
          }
	  }
	}
	
	//	float sum=0;
	for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++){
		/// UPPER
		sum_up[read_set_id]=results_against_set[cycle_id]->number_mapped_reads[read_set_id];
        //		compute_min_max_sum_starting_reads(results_against_set[read_set_id][cycle_id], &min_up[read_set_id], &max_up[read_set_id], &sum_up[read_set_id]);
		/// LOWER
		sum_lo[read_set_id]=results_against_set[cycle_id+1]->number_mapped_reads[read_set_id];
		//compute_min_max_sum_starting_reads(results_against_set[read_set_id][cycle_id+1], &min_lo[read_set_id], &max_lo[read_set_id], &sum_lo[read_set_id]);
	}
    
    if (!standard_fasta)
    {
        float rank = rank_phi(sum_up,sum_lo,number_of_read_sets);
        
        // UPPER PATH
        //fprintf(out, ">%s%s|", comment,results_against_set[cycle_id]->comment);
        fprintf(out, "%2f >%s%s|", rank, comment,results_against_set[cycle_id]->comment);
        for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
            fprintf(out, "C%d_%d|",read_set_id+1,sum_up[read_set_id]);
        if (qual)
            for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
                fprintf(out, "Q%d_%d|",read_set_id+1,avg_up[read_set_id]);
        fprintf(out, "rank_%.5f",rank);
//#ifdef GET_ONLY_UPPER_CHARS
        if(map_snps)
            fprintf(out, ";%s%s%s", results_against_set[cycle_id]->left_extension, results_against_set[cycle_id]->w, results_against_set[cycle_id]->right_extension);
//#else
        else
            fprintf(out, ";%s", results_against_set[cycle_id]->w);
//#endif
        fprintf(out, ";");
        
        // LOWER PATH
        fprintf(out, ">%s%s|", comment, results_against_set[cycle_id+1]->comment);
        for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
            fprintf(out, "C%d_%d|",read_set_id+1,sum_lo[read_set_id]);
        if ( qual )
            for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
                fprintf(out, "Q%d_%d|",read_set_id+1,avg_lo[read_set_id]);
        fprintf(out, "rank_%.5f",rank);
//#ifdef GET_ONLY_UPPER_CHARS
        if(map_snps)
            fprintf(out, ";%s%s%s", results_against_set[cycle_id+1]->left_extension, results_against_set[cycle_id+1]->w, results_against_set[cycle_id+1]->right_extension);
//#else
        else
            fprintf(out, ";%s", results_against_set[cycle_id+1]->w);
//#endif

        fprintf(out, "\n");
    }
    else
    {
        // UPPER PATH
        fprintf(out, ">%s%s|", comment,results_against_set[cycle_id]->comment);
        for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
            fprintf(out, "C%d_%d|",read_set_id+1,sum_up[read_set_id]);
        if (qual)
            for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
                fprintf(out, "Q%d_%d|",read_set_id+1,avg_up[read_set_id]);
//#ifdef GET_ONLY_UPPER_CHARS
        if(map_snps)
            fprintf(out, ";%s%s%s", results_against_set[cycle_id]->left_extension, results_against_set[cycle_id]->w, results_against_set[cycle_id]->right_extension);
//#else
        else
            fprintf(out, ";%s", results_against_set[cycle_id]->w);
//#endif

        
        // LOWER PATH
        fprintf(out, ">%s%s|", comment, results_against_set[cycle_id+1]->comment);
        for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
            fprintf(out, "C%d_%d|",read_set_id+1,sum_lo[read_set_id]);
        if ( qual )
            for(read_set_id=0;read_set_id<number_of_read_sets;read_set_id++)
                fprintf(out, "Q%d_%d|",read_set_id+1,avg_lo[read_set_id]);
//#ifdef GET_ONLY_UPPER_CHARS
        if(map_snps)
            fprintf(out, ";%s%s%s", results_against_set[cycle_id+1]->left_extension, results_against_set[cycle_id+1]->w, results_against_set[cycle_id+1]->right_extension);
//#else
        else
            fprintf(out, ";%s", results_against_set[cycle_id+1]->w);
//#endif
    }

	
}
#endif


/**
 * checks if at least one red set provide read coherency for a path.
 */
inline int one_coherent(const p_fragment_info * results_against_set, int cycle_id, int number_of_read_sets){
	int i;
	for(i=0;i<number_of_read_sets;i++){
	  if(results_against_set[cycle_id]->read_coherent[i]) return 1;
		
	}
	return 0;
}

void print_results(FILE * coherent_out, FILE * uncoherent_out,  const p_fragment_info * results_against_set, const int number_of_read_sets, int nb_events_per_set, int qual, const char map_snps){
	int i;
	int nb_read_coherent=0;
	int nb_unread_coherent=0;
	//printf("number ofread sets = %d\n", number_of_read_sets);

	 //
	 //                 C1           C2           C3 ....
	 // path1 (i)      [0/1]        [0/1]        [0/1]...
	 // path2 (i+1)    [0/1]        [0/1]        [0/1]...
	 //
	 // event is kept only if each line has at least one "1" per line:
	 //

	

	for(i=0;i<nb_events_per_set*2;i+=2){
		if(one_coherent(results_against_set,i,number_of_read_sets) && one_coherent(results_against_set,i+1,number_of_read_sets))
		{
			nb_read_coherent++;
			print_couple_i("",coherent_out, "", results_against_set, i, number_of_read_sets, qual, map_snps);
		}
		else{
			nb_unread_coherent++;
			print_couple_i("", uncoherent_out, "", results_against_set, i, number_of_read_sets, qual, map_snps);
		}
	}

	printf("Among %d mouths:\n\t%d read coherent and\n\t%d not read coherent\n",
			nb_events_per_set, nb_read_coherent, nb_unread_coherent);
}








