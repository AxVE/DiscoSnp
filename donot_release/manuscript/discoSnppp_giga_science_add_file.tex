%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
\documentclass{bmcart}

%%% Load packages
%\usepackage{amsthm,amsmath}
%\RequirePackage{natbib}
%\RequirePackage{hyperref}
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \def\includegraphic{}
% \def\includegraphics{}



%%% Put your definitions there:
\startlocaldefs

\usepackage{xspace}
\usepackage{amsmath}
\newcommand{\disco}{{\it DiscoSnp}\xspace}
\newcommand{\discopp}{{\it DiscoSnp++}\xspace}
\newcommand{\co}{{\it cortex}\xspace}

\usepackage{graphicx}


\usepackage{algorithm} %ctan.org\pkg\algorithms
\usepackage{algpseudocode}

\endlocaldefs


%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Technical Note}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{{\it DiscoSnp++}: Additional File}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
   addressref={aff1},                   % id's of addresses, e.g. {aff1,aff2}
   corref={aff1},                       % id of corresponding address, if any
   % noteref={n1},                        % id's of article notes, if any
   email={pierre.peterlongo@inria.fr}   % email address
]{\inits{PP}\fnm{Pierre} \snm{Peterlongo}}
 \author[
    addressref={aff1},
    email={erwan.drezen@inria.fr}
 ]{\inits{ED}\fnm{Erwan} \snm{Drezen}}
 \author[
    addressref={aff1},
    email={claire.lemaitre@inria.fr}
 ]{\inits{ED}\fnm{Claire} \snm{Lemaitre}}
 \author[
    addressref={aff1},
    email={chloe.riou@inria.fr}
 ]{\inits{ED}\fnm{Chlo√©} \snm{Riou}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%                           % unique id
  \orgname{GenScale, INRIA Rennes Bretagne-Atlantique, IRISA}, % university, etc
  \street{Campus de Beaulieu},                     %
  %\postcode{}                                % post or zip code
  \city{Rennes},                              % city
  \cny{France}                                    % country
}
% \address[id=aff2]{%
%   \orgname{Marine Ecology Department, Institute of Marine Sciences Kiel},
%   \street{D\"{u}sternbrooker Weg 20},
%   \postcode{24105}
%   \city{Kiel},
%   \cny{Germany}
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{artnotes}
%\note{Sample of title note}     % note to the article
% \note[id=n1]{Equal contributor} % note, connected to author
\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% Please refer to the Instructions for     %%
%% authors on http://www.biomedcentral.com  %%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{abstractbox}
%
% \begin{abstract} % abstract
% \parttitle{First part title} %if any
%
% NGS data provides an unprecedented access to life mechanisms. In particular these data enable to detect polymorphisms such as SNPs and indels.
% These polymorphisms represent a fundamental source of information in agronomy, environment or medicine.  Thus detecting these polymorphisms is a routine task with NGS data. The main methods for their prediction usually need a reference genome. However, non-model organisms and highly divergent genomes such as in cancer studies  are more and more investigated.
%
% \parttitle{Second part title} %if any
% Text for this section.
% \end{abstract}
%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%                                          %%
% %% The keywords begin here                  %%
% %%                                          %%
% %% Put each keyword in separate \kwd{}.     %%
% %%                                          %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% \begin{keyword}
% \kwd{sample}
% \kwd{article}
% \kwd{author}
% \end{keyword}
%
% % MSC classifications codes, if any
% %\begin{keyword}[class=AMS]
% %\kwd[Primary ]{}
% %\kwd{}
% %\kwd[; secondary ]{}
% %\end{keyword}

% \end{abstractbox}
%
%\end{fmbox}% uncomment this for twcolumn layout

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Main Body begins here                %%
%%                                          %%
%% Please refer to the instructions for     %%
%% authors on:                              %%
%% http://www.biomedcentral.com/info/authors%%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%% See the Results and Discussion section   %%
%% for details on how to create sub-sections%%
%%                                          %%
%% use \cite{...} to cite references        %%
%%  \cite{koon} and                         %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}    %%
%%  \nocite{smith,marg,hunn,advi,koha,mouse}%%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% start of article main body
% <put your article body there>

%%%%%%%%%%%%%%%%
%% Background %%
%%

\section*{Validation of predictions and precision/recall computations}
Both on real datasets or synthetic ones, predicted polymorphisms can be compared to a reference set. In all the performed tests, one dispose from a reference genome that is used in the purpose of simulating and validating predictions.
Whatever the tested method, the predicted polymorphisms are validated using the following process:
\begin{itemize}
	\item All predicted sequences are fully mapped using Gassst~\cite{Rizk2010} on the reference genome with a least 90\% similarity.
	\item For SNPs:
	\begin{itemize}
		\item For each couple of sequences predicting one or more SNPs: if one or the two sequence(s) map the reference genome: for each predicted SNP of the mapped sequence(s), if its position matches exactly a position on which a SNP was simulated, then this SNP is considered as a True Positive (TP).
	\end{itemize}
	\item For indels:
	\begin{itemize}
		\item If one or the two sequence(s) of a predicted indel matches a simulated indel position, then such a prediction is considered as a True Positive (TP).
	\end{itemize}
	\item A predicted polymorphism that is not a True Positive is a False Positive (FP).
	\item A simulated polymorphism not mapped by a predicted polymorphism is a False Negative (FN).
\end{itemize}

The precision defined by $$precision=\frac{number TP}{number TP+ number FP}$$ and the recall is defined by $$recall=\frac{number TP}{number TP+ number FN}.$$

Note that in the case of real datasets, the $precision$ is meaningless as the reference sets are not exhaustive. The main manuscript does not provide $precision$ for real read sets.

\section*{Simulation experiments}


\subsection*{Two to $n$ E. Coli datasets: simulations and experiments}
\subsubsection*{Simulations}
We propose an experiment simulating more than two haploid bacterial individuals. For doing this, we created 30 copies (that we call individuals) of the E. coli K-12 MG1655 strain. We then simulated SNPs with a uniform distribution such that $\approx$ 4200 SNPs ($\approx$0.1\% of the genome length) are common to any pair of individuals, half this number is common to any trio of individuals, a third to any quadruplet, and so on. With this strategy, while considering all the 30 individuals together, 69 600 SNP sites were generated, covering $\approx$1.5\% of the genome. We also simulated indels following exactly the same process, with a ratio of one indel for ten SNPs. 

We simulated a 40x sequencing of each of the 30 individuals, with 100-bp reads and 0.1\% error rate. Thus, 1,855,870 reads were generated per read set. 

\subsubsection*{Experiments}
Experiments were made on subsets of two Coli individuals (the two first read sets), three individuals (the three first read sets), and so on up to 30 experiments. The command used are reported Table~\ref{tab:colicommands}. 


\begin{table*}[ht]
	\hrule~\\
\emph\textbf{{\discopp}}
	\scriptsize\begin{verbatim}
	for ((i=2;i<=31;i++)); do
	#Prepare input parameters
	 list=""; for((j=0;j<i;j++)); do list=$list" "coli_muted_n_30_genome_$j\_reads.fasta; done
	#Run discoSnp++
	 run_discoSnp++.sh -r  "$list" -p dsc_$i\_genomes -P 4 -D 10
	done
	\end{verbatim}	\normalsize
~\hrule~\\
\emph\textbf{{\co}}
\scriptsize\begin{verbatim}
#(needs a compilation per number of input read sets):
for ((i=1;i<31;i++)); do make MAXK=31 NUM_COLS=$i cortex_var; done 

#Prepare input parameters
for ((i=0;i<30;i++)); do echo coli_muted_n_30_genome_$i\_reads.fasta > ind$i; done
for ((i=2;i<31;i++)); do 
 for ((j=0;j<i;j++)); do echo -e "IND$j\tind$j\t.\t." >> INDEX$i; done; 
done

#Prepare data
for ((i=0;i<30;i++)); do
 cortex_var_31_c2 --se_list ind$i --kmer_size 31 --mem_height 20 --mem_width 75 \ 
  --dump_binary genome_$i\_reads.ctx  --sample_id sample$i --remove_low_coverage_supernodes 3
done

for ((i=0;i<30;i++)); do
#Prepare input parameters
 echo  "genome_$i\_reads.ctx" > ind$i\_ctx
 for ((i=0;i<$nb;i++));
  do echo ind$i\_ctx >> my_cortex_list_ctx_$nb
 done
#Detect variants
 cortex_var_31_c$nb --colour_list my_cortex_list_ctx_$nb --kmer_size 31 --mem_height 22 --mem_width 75 \
  --detect_bubbles1 0/1 --output_bubbles1 my_res_cortex_$nb --remove_low_coverage_supernodes 3 
done
	\end{verbatim}	\normalsize
~\hrule~\\
\emph\textbf{Hybrid approach}
\scriptsize\begin{verbatim}
#Assembly
SOAPdenovo-63mer pregraph -s soap.config  -o soapNAR30A -K $k -d 5 
SOAPdenovo-63mer contig -g soapNAR30A

#remove contigs whose size is < 100:
python ./filter_fasta_by_length.py soapNAR30A.contig NAR30A_ref.contigs.fa 100 
mv  soapNAR30A.contig  NAR30A_ref.contigs.fa
bowtie2-build -f NAR30A_ref.contigs.fa NAR30A_ref.contigs_index  ;

#Map reads
basen=coli_muted_n_30_genome_
suffixn=_reads.fasta
for i in $(seq 0 30); do
 bowtie2 -f --non-deterministic --threads 8  --rg-id "read$i" --rg "SM:read$i" \
  --rg "PL:Illumina" --rg "LB:simumima" -x NAR30A_ref.contigs_index  -U ${basen}${i}${suffixn} \
  |  samtools view -bS - >  NAR30A_${i}_bw2.bam;
 samtools sort  -m 25000000000 NAR30A_${i}_bw2.bam NAR30A_${i}_bw2.sorted.bam
 mv NAR30A_${i}_bw2.sorted.bam.bam NAR30A_${i}_bw2.bam
 samtools index NAR30A_${i}_bw2.bam
 samtools flagstat NAR30A_${i}_bw2.bam > NAR30A_${i}_bw2.flagstat
done

#Variant calling
samtools faidx coli_muted_ref.contigs.fa
java -Xmx4g -jar ./CreateSequenceDictionary.jar  R=coli_muted_ref.contigs.fa  O=coli_muted_ref.contigs.dict
gpar="-I coli_muted_0_bw2.bam"
for i in $(seq 1 30); do
 gpar="$gpar -I coli_muted_${i}_bw2.bam"
 java -Xmx8g -jar /softs/local/GATK/2.8.1/GenomeAnalysisTK.jar -R coli_muted_ref.contigs.fa -T UnifiedGenotyper \
 -glm BOTH ${gpar} -o coli_muted_both_${i}.vcf
done

	\end{verbatim}	\normalsize
	\caption{Commands used for calling SNPs and indels from 2 to 30 E. Coli read sets ({coli\_muted\_n\_30\_genome\_$i$\_reads.fasta} for $i$ in $[1,30]$) with \discopp, \co or the hybrid approach. \label{tab:colicommands}}
\end{table*}




\subsection*{Two human read sets: simulations and experiments}
\subsubsection*{Simulations}
An experiment was performed on two human diploid read sets. This experiment applied on human chromosome 1, (GRCh37/hg19 reference assembly version), $\approx249$ million base pairs. SNPs and indels were simulated following the 1000 genome project~\cite{Altshuler2012} predictions. Precisely, from the phase 1 vcf file~\cite{vcf}, we extracted SNPs and indels of individuals HG00096 and HG00100. Variants having the same genotypes in both individuals were discarded. For each of the two individuals, two version of the chromosome were created. On each of these two versions, SNPs and indels were placed following the VCF file, i.e., $0|0$: no modification of the chromosomes, $0|1$: modification of one of the two chromosomes (randomly chosen), $1|1$: modification of the two chromosomes. 

For each individual, we simulated a 40x illumina sequencing with 0.1\% error rate (20x per chromosome). Thus, 99,600,000 reads were generated per read set. 

\subsubsection*{Experiments}
Experiments were performed using \discopp, \co and the hybrid approach using the commands indicated Table~\ref{tab:humancommands}.

\begin{table*}[ht]
	\hrule~\\
\emph\textbf{{\discopp}}
	\scriptsize\begin{verbatim}
	run_discoSnp++.sh -r "humch1_00096_reads.fasta humch1_00100_reads.fasta" -P 4 -D 10
	\end{verbatim}	\normalsize
~\hrule~\\
\emph\textbf{{\co}}
\scriptsize\begin{verbatim}
#Prepare data
for i in 096 100; do
 cortex_var_31_c2 --se_list data$i.txt --kmer_size 31 --mem_height 25 --mem_width 100 \
  --dump_binary genome_$i\_reads.ctx  --sample_id sample$i --remove_low_coverage_supernodes 3
done

#Prepare parameters
for i in 096 100; do
 echo  "genome_$i\_reads.ctx" > ind$i\_ctx
 echo ind$i\_ctx >> my_cortex_list_ctx
done

#Detect variants
cortex_var_31_c2 --colour_list my_cortex_list_ctx --kmer_size 31 --mem_height 25 --mem_width 100 \
 --detect_bubbles1 0,1/0,1 --output_bubbles1 my_res_cortex --remove_low_coverage_supernodes 3 
 
	\end{verbatim}	\normalsize
~\hrule~\\
\emph\textbf{Hybrid approach}
\scriptsize\begin{verbatim}
#Assembly
SOAPdenovo-63mer pregraph -s soap.config  -o soaphum -K $k -d 5 
SOAPdenovo-63mer contig -g soaphum

#Remove contigs whose size is < 100:
./filter_fasta_by_length.py soaphum.contig hum_ref.contigs.fa 100
mv  soaphum.contig  hum_ref.contigs.fa

#Align reads
${path_bw2}bowtie2-build -f hum_ref.contigs.fa hum_ref.contigs_index 
for i in 096 100; do
 bowtie2 -f --non-deterministic --threads 8  --rg-id "read$i" --rg "SM:read$i" --rg "PL:Illumina" \ 
 --rg "LB:simumima" -x hum_ref.contigs_index  -U /WORKS/tests_human/data/humch1_00$i\_reads.fasta \ 
 |  ${path_sam}samtools view -bS - >  hum_${i}_bw2.bam;
 samtools sort  -m 25000000000 hum_${i}_bw2.bam hum_${i}_bw2.sorted.bam
 mv hum_${i}_bw2.sorted.bam.bam hum_${i}_bw2.bam
 samtools index hum_${i}_bw2.bam
 samtools flagstat hum_${i}_bw2.bam > hum_${i}_bw2.flagstat
done

#Variant calling
samtools faidx hum_ref.contigs.fa
java -Xmx4g -jar ./CreateSequenceDictionary.jar  R=${ref}  O=hum_ref.contigs.dict
time ~grizk/bin/memusage java -Xmx62g -jar /softs/local/GATK/2.8.1/GenomeAnalysisTK.jar \
-R ${ref} \
-T HaplotypeCaller \
-I ${prefix}_096_bw2.bam -I ${prefix}_100_bw2.bam \
-o ${prefix}_both_HaplotypeCaller.vcf
	\end{verbatim}	\normalsize
	\caption{Commands used for calling SNPs and indels from two human chromosome 1 read sets (humch1\_00096\_reads.fasta humch1\_00100\_reads.fasta) with \discopp, \co or the hybrid approach. \label{tab:humancommands}}
\end{table*}


\subsubsection*{GATK parameters} % (fold)
As mentioned in the manuscript, we used GATK either simply calling SNPs and indel using the \emph{UnifiedGenotyper} option as shown Table~\ref{tab:humancommands} or using the reads realignment and the \emph{HaplotypeCaller}.

We decided not to present results using the reads realignment and the \emph{HaplotypeCaller} as this does not improve significantly the prediction precision and recall (see Figure~\ref{fig:figures_roc_gatk}) and as the execution time is three times longer (from approximately 19h to 54h for this experiment). 

\begin{figure}[h]
	\centering
		\includegraphics[width=.9\textwidth]{figures/roc_gatk.png}
	\caption{Comparison of the hybrid results on the human dataset depending on the GATK pipeline. ``\emph{realign+haplo}'' stands for the using the GATK \emph{realigner} and of the \emph{HaplotypeCaller}, while ``{unified}'' stands for the \emph{UnifiedGenotyper} only.}
	\label{fig:figures_roc_gatk}
\end{figure}



\section*{Saccharomyces cerevisiae: experiment}
We used reads provided by the Kvitek~\cite{Kvitek2013} study. The 24 read sets were downloaded from the NCBI Sequence Read Archive (with the accession number SRA054922), and processed to remove barcode and adapter sequences as in the initial study. \discopp was run independently on populations E1, E2
and E3. For each population, \discopp was applied on the eight read sets corresponding to the eight time points, with
the default parameters and $c=11$, $D=60$ (searching for indels of length at most 60) and $P=4$ (authorizing up to 4 close SNPs in a unique bubble).

The command were the following:

\scriptsize\begin{verbatim}
run_discoSnp++.sh -r "`ls data/E1_gen*`" -D 60 -P 4 -c 11
run_discoSnp++.sh -r "`ls data/E2_gen*`" -D 60 -P 4 -c 11
run_discoSnp++.sh -r "`ls data/E3_gen*`" -D 60 -P 4 -c 11
\end{verbatim}	\normalsize
\section{VCF creation} % (fold)
\subsection{Mapping predictions on a reference genome} % (fold)
Depending on the user choice and the availability of a reference genome, \discopp may map its predictions. We performed tests using BWA~\cite{bwa} and we provide an automatic pipeline based on this tool output. %However, user may provide a BAM file generated by any other alignment tool. 


\begin{algorithm}
 \begin{algorithmic}[1]
 \State Map \discopp output on the reference genome, authorizing at most $t$ errors (indels and mismatches)
 \For{each \discopp prediction $p$ (couple of sequence \{$S_A$,$S_B$\})}
 \For{each position of the prediction}
 \If{$d$ (mapping distance) $<=D$ (best mapping distance)}
 \State Keep the mapping distance as best mapping distance
 \EndIf
 \EndFor 
 \For{each position of the prediction}
 \If{$d==D$}
 \State Compute $U=\{$genomic positions  where $S_A$ and/or $S_B$ mapped at distance $==D\}$
 \EndIf
 \EndFor
 \If{$|U|==1$}
 \State Set prediction $p$ as Mapped at this unique position (within distance $d$)
 \State Break
 \EndIf
 \If{$|U|>1$}
 \State Set prediction $p$ Multiple Mapped
 \State Break
 \EndIf
 \EndFor
 \If{$p$ never set as ``Mapped'' (Unique position or Multiple Mapping)}
 \State  {set $p$ as ``Unmapped''}
 \EndIf
 \EndFor
 \end{algorithmic}
 \caption{Mapping and validation of mapped variants}
 \label{alg:mapping}
\end{algorithm}
The reference genome and the predictions may present differences due to distinct individuals, bad assembly of the reference or reference species distant from analyzed reads. Thus, errors (indel and mismatches) are authorized during the mapping. By default we use BWA authorizing at most $t=4$ errors and using a seed of length $10$.
Each prediction (each couple of sequence \{$S_A$,$S_B$\}) is considered as mapped at a unique genomic position (and therefor validated) if there exists a minimal distance $d\leq t$ for which $S_A$ and/or $S_B$ have a unique match on the reference genome. In this case, the position of this match is indicated in the VCF file. Algorithm~\ref{alg:mapping}, presents how this unique position, if exists, is detected for each predicted variant.


\subsection{Detailed VCF content}
The proposed VCF file contains the following fields:
\begin{itemize}
	\item \textbf{CHROM}: Chromosome id where the prediction is mapped, or `.' if no reference genome provided or if no (unique) mapping of the variant
	\item \textbf{POS}: 
	\begin{itemize}
		\item If a reference genome is provided and if the couple is mapped on a unique position: position of the variant (with the first base having the position 1)
		\item If a reference genome is provided and if the couple is not uniquely mapped: one of the positions of the variant (the first reported by BWA)
		\item Else (no reference genome provided or couple unmapped):position on the local assembly predict by \discopp (path, unitig or contig)
		%position of the variant from the beginning of the upper case \discopp prediction (excluding the eventual left local assembly)
	\end{itemize}
	\item \textbf{ID}: identification of the SNP or the indel. 
	\item \textbf{REF}: \\
	For SNPs:
	\begin{itemize}
		\item If one of the two predictions is mapped on the genome: the nucleotide present on the reference genome at the variant position.
		\item Else, or if no reference genome provided: the lexicographically smallest of the two variants
		\item In case of close SNPs : the first is defined as previously described. The following SNPs are those located on the same path 
	\end{itemize}
	For Indels: one of the two predictions is longer than the other.% We call \emph{insert} the sequence which differentiates the two sequences.
	\begin{itemize}
		\item If the smallest prediction is mapped on the genome: the nucleotide present on the reference genome at the variant position-1.
		\item If the longest prediction is mapped on to the genome: the sequence of the reference genome from the variant position-1 to the variant position+size of the indel.
		\item Else, or if no reference genome provided: the lexicographically smallest of the two variants
	\end{itemize}
	Remark: the REF (and ALT) sequences are extracted from the reference genome is forward strand. If the reverse complement of the prediction is mapped, the reported REF and ALT sequences correspond to the reverse complement of the \discopp predictions.
	\item \textbf{ALT}: The variant non reported as the ``REF'' variant
	\item \textbf{QUAL}: `.'
	\item \textbf{FILTER}: 
	\begin{itemize}
		\item PASS if the variant is mapped on a unique position
		\item MULTIPLE if the variant is mapped on multiple positions
		\item `.' if no reference genome provided
	\end{itemize}
	\item \textbf{INFO}:
	\begin{itemize}
		\item \textbf{Ty}: Type of variant: `SNP', `INS' or `DEL'
		\item \textbf{Rk}: Rank of the prediction computed by \discopp
		\item \textbf{UL}: Length of the left unitig (`None' if not computed)
		\item \textbf{UR}: Length of the right unitig (`None' if not computed)
		\item \textbf{CL}: Length of the left contig (`None' if not computed)
		\item \textbf{CR}: Length of the right contig (`None' if not computed)
		\item \textbf{Genome}: Applies only for SNPs when a reference genome is provided (`.' for indels and when no reference genome provided). Nucleotide on the reference genome at the variant position.   \textbf{Important Remark}: This is equal to the ``REF'' field only if one of the two prediction matches the reference.
		\item \textbf{Sd}: Applies only when a reference genome is provided (`.' if no reference genome provided or if the variant was not mapped). Strand of the prediction mapping. `1': Forward, `-1': Reverse. \textbf{Important Remark}: Fields ``REF'', ``ALT'' and ``AR'' are based on the mapped predictions. %If Sd is `1' then these fields correspond to the \discopp prediction, else if Sd is `-1', then they correspond to the reverse complement of the \discopp predictions. 
		
	\end{itemize}
			
	\item \textbf{FORMAT}: specificying the data type and the order of this data.
		\begin{itemize}
			\item \textbf{GT}:Genotype for the REF prediction (given by discoSnp++). The allele are separated by `|' in case of snp and indel (genotype unphased) or by `/' for close snps (genotype phased)
			\item \textbf{DP}:Cumulated depth accross samples (sum)
			\item \textbf{PL}:Phred-scaled Genotype Likelihoods
			\item \textbf{AD}:Depth of each allele by sample
		\end{itemize}
	\item \textbf{GENOTYPE}:all informations of the format field by sample
\end{itemize}

\section{Genotyping} % (fold)
\begin{align*}
       c_u &: \text{Coverage upper path} \\
       c_l &: \text{Coverage lower path}\\
       err &: \text{Uniform error rate} (0.01) \\
       prior &: \text{heterozygous prior} (0.33)\\
       like_{0/0}&=-10\log_{10}\left((1-err)^{c_u}\times err^{c_l}\times C_{c_u+c_l}^{c_u} \times \frac{1-prior}{2}\right)\\
       like_{1/1}&=-10\log_{10}\left(err^{c_u}\times (1-err)^{c_l}\times C_{c_u+c_l}^{c_u} \times \frac{1-prior}{2}\right)\\
       like_{0/1}&=-10\log_{10}\left(\left(\frac{1}{2}\right)^{c_u+c_l}\times prior\right)\\
       min(&like_{0/0},like_{1/1},like_{0/1}) \Rightarrow 0/0, \text{or } 1/1, \text{or } 0/1\\
\end{align*}

\section{Algorithm: Bubble walking}

\begin{algorithm}
 \begin{algorithmic}[1]
\State{\#Search for SNPs}
 \For{each couple of successor kmers $kmer_1,kmer_2$}
 \State{expand($kmer_1,kmer_2$, 1 SNPs already detected up to $P$ authorized close SNPs)}
 \EndFor
\State{\#Search for Indels (whatever predicted SNPs)}
\For{each path selected as the $extended\_path$}
\State{Breadth first extend the $extended\_path$ (up to $D$ nuc.)}
\If{Last character of the extension == last char. of the non expanded $kmer$}
\State{expand($kmer_1,kmer_2$, 1 variant already detected up to $1$ authorized variant)}
\EndIf
\EndFor
 \end{algorithmic}
 \caption{SNP \& Indels caller}
\end{algorithm}


\begin{algorithm}
 \begin{algorithmic}[1]
 \State {Test branching $kmer_1,kmer_2$. \textbf{Exit if necessary}}
 \State {Get $kmer_1^{+}$ and $kmer_2^{+}$ the unique possible extensions of $kmer_1$ and $kmer_2$ with the same $\alpha$. Note that with branching=2: there may exist several couple  $kmer_1^{+}$, $kmer_2^{+}$, both extended with the same $\alpha$} 
 \If {$kmer_1^{+} == kmer_2^{+}$}
 \State {Finish the bubble \& \textbf{stop the expand} }
 \Else
 \State {Expand($kmer_1^{+}$, $kmer_2^{+}$, 0 new SNP detected up to $P$ authorized close SNPs)}
 \EndIf
 \If {Number detected close SNPs $<P$}
 \For{ $kmer_1^{+}$ and $kmer_2^{+}$ two kmers extending  $kmer_1$ and $kmer_2$ with distinct $\alpha, \beta$}\If {$kmer_1^{+} == kmer_2^{+}$}
 \State {Finish the bubble \& \textbf{stop the expand} }
 \Else
 \State {Expand($kmer_1^{+}$, $kmer_2^{+}$, 1 new SNP detected up to $P$ authorized close SNPs)}
 \EndIf
 \EndFor
 \EndIf
 \end{algorithmic}
 \caption{Expand two kmers}
\end{algorithm}

\bibliographystyle{bmc-mathphys} % Style BST file
\bibliography{discoSnppp_giga_science}      % Bibliography file (usually '*.bib' )
\end{document}
